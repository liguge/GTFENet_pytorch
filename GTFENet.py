import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np
import re
import scipy.io as sio
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score,recall_score, f1_score, roc_curve, roc_auc_score, auc
from sklearn.preprocessing import label_binarize
import pandas as pd




def cal_index(y_true, y_pred):
    '''
    Calculate Accuracy, Recall, Precision, F1-Score
    https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin
    '''
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, average='macro', labels=np.unique(y_pred))
    recall = recall_score(y_true, y_pred, average='macro', labels=np.unique(y_pred))
    F1_score = f1_score(y_true, y_pred, average='macro', labels=np.unique(y_pred))

    return acc, prec, recall, F1_score

def cal_auc_roc(y_true, y_pred_score, num_class=7):
    # https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html
    y_true_one_hot = label_binarize(y_true, classes=list(range(num_class)))

    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(num_class):
        fpr[i], tpr[i], _ = roc_curve(y_true_one_hot[:, i], y_pred_score[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])


    return roc_auc, fpr, tpr

#%%
# def conv1d_blk(x,filters,kernel_size,strides,padding):
#     x1 = layers.Conv1D(filters, kernel_size, strides, padding)(x)
#     x2 = layers.BatchNormalization()(x1)
#     x3 = layers.Activation('relu')(x2)
#     x3 = layers.Dropout(0.2)(x3)
#
#     return x3


def feature_map_reshape12(x):
    '''
    - Description: Covert the 1D feature map into 2D feature map
    - Input: x, shape:B*L*C, x is batch of 1D feature maps with C channels. - - Note that the length L should be 2^k, where k is positive integer
    - Output:y, shape: B*H*W*C

    Example:
    input_shape = (11, 512, 7)
    x = tf.random.normal(input_shape)
    output_shape: TensorShape([11, 16, 32, 7])
    '''

    x_shape = x.shape
    len_feature_map1d = x_shape[2]

    tmp = np.log2(len_feature_map1d)
    if int(tmp % 2) == 0:
        h = int(2**(tmp/2))
        w = int(len_feature_map1d/h)
    elif int(tmp % 2) == 1:
        h = int(2**((tmp-1)/2))
        w = int(len_feature_map1d/h)


    samples_1d = x
    feature_map_shape2d = [-1, x_shape[1], h, w]
    # feature_map_shape2d = [-1, x_shape[2], w, h] # there is no significant difference between the h-first and w-first

    samples_2d = torch.reshape(samples_1d, feature_map_shape2d)
    y = samples_2d

    return y


def gram_blk(x):
    '''
    - Description: Calculate the Gram Enhanced feature map based on 2D feature map
    - Input: x, shape: B*H*W*C
    - Output: y = (x*x.T)*x*(x.T*x)
    '''
    xg1 = torch.einsum('bcij,bcjk->bcik', torch.permute(x, (0, 1, 3, 2)), x)
    xg2 = torch.einsum('bcij,bcjk->bcik', x, torch.permute(x, (0, 1, 3, 2)))
    y = torch.einsum('bcij,bcjk->bcik', xg2, x)
    y = torch.einsum('bcij,bcjk->bcik', y, xg1)
    return y


def feature_map_reshape21(x):
    '''
    - Description: Covert feature maps (generated by gram_blk) from 2D to 1D
    - Input: x, shape:B*H*W*C, x is batch of 2D feature maps with C channels.
    - Output:y, shape: B*L*C
    - Note that the length L should be 2^k, where k is positive integer


    Example:
    input_shape = [11, 16, 32, 7]
    x = tf.random.normal(input_shape)
    output_shape: TensorShape([11, 512, 7])
    '''

    x_shape = x.shape
    len_feature_map1d = x_shape[2]*x_shape[3]
    feature_map_shape2d = [-1,  x_shape[1], len_feature_map1d]
    y = torch.reshape(x, feature_map_shape2d)

    return y

def batch_gram_blk(x):

    x = feature_map_reshape12(x)
    x = gram_blk(x)
    x = feature_map_reshape21(x)
    # y = layers.LayerNormalization(axis=1)(x3)
    y = F.layer_norm(x, normalized_shape=(x.size()[1], x.size()[2]))
    return y

def batch_fft_blk(x):
    data_length = x.shape[2]
    # x1 = x
    x = torch.abs(torch.fft.rfft(x)) / data_length
    # x3 = x2
    # x4 = layers.LayerNormalization(axis=1)(x3)
    x = F.layer_norm(x, normalized_shape=(x.size()[1], x.size()[2]))
    return x


class conv1d_blk(nn.Module):

    def __init__(self, in_channel, filters, kernel_size, strides, padding):
        super(conv1d_blk, self).__init__()
        self.conv1 = nn.Conv1d(in_channel, filters, kernel_size, strides, padding)
        self.bn1 = nn.BatchNorm1d(filters)
        self.act = nn.ReLU(inplace=True)
        self.drop = nn.Dropout(0.2)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.act(x)
        x = self.drop(x)
        return x


# def the_blk(xr0, xg0, xf0, ):
#     '''
#     disconnect the Fourier bridges, only Gramian bridge is kept.
#     '''
#     xr1 = conv1d_blk(xr0, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding)
#     xr1_g = batch_gram_blk(xr1)
#     xg0_c = conv1d_blk(xg0, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding)
#     xg1 = torch.concat([xr1_g, xg0_c], 2)
#     # xg1_0   = tf.concat([xr1_g,xg0_c], axis = 2)
#     # xg1 = conv1d_blk(xg1_0, filters = filters, kernel_size = 1, strides = 1, padding = padding) #notice that
#     xf1 = conv1d_blk(xf0, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding)
#
#
#     return xr1, xg1, xf1

class the_blk(nn.Module):

    def __init__(self, in_channel, filters=16, kernel_size=3, strides=1, padding=0):
        super(the_blk, self).__init__()
        self.conv1d_blk1 = conv1d_blk(in_channel, filters=filters, kernel_size=kernel_size, strides=strides,
                                      padding=padding)
        if in_channel == 1:
            self.conv1d_blk2 = conv1d_blk(in_channel=1, filters=filters, kernel_size=kernel_size, strides=strides,
                                          padding=padding)
            self.conv1d_blk3 = conv1d_blk(in_channel=2, filters=filters, kernel_size=kernel_size, strides=strides,
                                          padding=padding)
        else:
            self.conv1d_blk2 = conv1d_blk(2 * in_channel, filters=filters, kernel_size=kernel_size, strides=strides,
                                          padding=padding)
            self.conv1d_blk3 = conv1d_blk(in_channel, filters=filters, kernel_size=kernel_size, strides=strides,
                                          padding=padding)
    def forward(self, xr0, xg0, xf0):
        xr1 = self.conv1d_blk1(xr0)
        xr1_g = batch_gram_blk(xr1)
        xg0_c = self.conv1d_blk2(xg0)
        xg1 = torch.concat([xr1_g, xg0_c], 1)
        # xg1_0   = tf.concat([xr1_g,xg0_c], axis = 2)
        # xg1 = conv1d_blk(xg1_0, filters = filters, kernel_size = 1, strides = 1, padding = padding) #notice that
        xf1 = self.conv1d_blk3(xf0)
        return xr1, xg1, xf1

class the_model(nn.Module):

    def __init__(self, class_number=10):
        super(the_model, self).__init__()
        self.the_blk1 = the_blk(in_channel=1, filters=32, kernel_size=31, strides=1, padding=15)
        self.the_blk2 = the_blk(in_channel=32, filters=32, kernel_size=31, strides=2, padding=15)
        self.the_blk3 = the_blk(in_channel=32, filters=64, kernel_size=15, strides=2, padding=7)
        self.the_blk4 = the_blk(in_channel=64, filters=64, kernel_size=15, strides=2, padding=7)
        self.the_blk5 = the_blk(in_channel=64, filters=128, kernel_size=5, strides=2, padding=2)
        self.fc = nn.Linear(512, class_number)

    def forward(self, in_x):
        xr0 = in_x
        xg0 = batch_gram_blk(in_x)
        xg0_f = batch_fft_blk(xg0)
        xr0_f = batch_fft_blk(xr0)
        xf0 = torch.concat([xg0_f, xr0_f], 1)
        xr1, xg1, xf1 = self.the_blk1(xr0, xg0, xf0)
        xr1, xg1, xf1 = self.the_blk2(xr1, xg1, xf1)
        xr1, xg1, xf1 = self.the_blk3(xr1, xg1, xf1)
        xr1, xg1, xf1 = self.the_blk4(xr1, xg1, xf1)
        xr2, xg2, xf2 = self.the_blk5(xr1, xg1, xf1)
        x21 = F.adaptive_avg_pool1d(xr2, 1)
        x22 = F.adaptive_avg_pool1d(xg2, 1)
        x23 = F.adaptive_avg_pool1d(xf2, 1)
        x2 = torch.concat([x21, x22, x23], 1).squeeze()
        x2 = self.fc(x2)
        return x2


#%%
def normalization_processing(data):
    data_mean = data.mean()
    data_var = data.var()

    data = data - data_mean
    data = data / data_var

    return data

def wgn(x, snr):

    snr = 10**(snr/10.0)
    xpower = np.sum(x**2)/len(x)
    npower = xpower / snr

    return np.random.randn(len(x)) * np.sqrt(npower)


def add_noise(data, snr_num):

    rand_data = wgn(data, snr_num)
    data = data + rand_data

    return data
if __name__ == '__main__':
    input = torch.randn(2, 1, 1024)
    model = the_model()
    output = model(input)
    print(output.size())